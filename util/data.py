# Handles the data importing and small preprocessing for the interaction network.

import os
import numpy as np
import tensorflow as tf
import functools

from .terminal_colors import tcols


class Data:
    """Data class to store the data to be used in learning for the interaction network.

    Attributes:
        fpath: Path to where the data files are located.
        fname: Name of the data to import, without train, test, val flags.
        train_events: Number of events for the training data, -1 to use all.
        val_events: Number of events for the validaiton data, -1 to use all.
        test_events: Number of events for the testing data, -1 to use all.
        jet_seed: Seed used in shuffling the jets.
        seed: The seed used in any shuffling that is done to the data.
    """

    def __init__(self, fpath: str, fname: str):
        self._fpath = fpath
        self._fname = fname
        self.feats = fname.split("_")[4]

        # self.buffer_size = buffer_size
        # self.batch_size = batch_size
        # self.jet_seed = jet_seed
        # self.seed = seed

        self.train_data = self._load_data("train")
        self.valid_data = self._load_data("val")
        self.test_data = self._load_data("test")

        self.train_target = self._load_target("train")
        self.valid_target = self._load_target("val")
        self.test_target = self._load_target("test")

        self.ntrain_jets = self.train_data.shape[0]
        self.nvalid_jets = self.valid_data.shape[0]
        self.ntest_jets = self.test_data.shape[0]
        self.ncons = self.test_data.shape[1]
        self.nfeat = self.test_data.shape[2]
        self._success_message()

    @classmethod
    def kfolded_data(cls, fpath: str, fnames_train: list, fname_test: str):
        """Alternative constructor for kfolded data."""
        self._fpath = fpath
        self._fnames_train = fnames_train
        self._fname_test = fname_test

        # self.train_data =

    def _load_data(self, data_type: str):
        """Load data from the data files generated by the pre-processing scripts.

        Set the batch size and apply shuffling at the jet level.

        Args:
            data_type: The type of data that you want to load: val, train or test.

        Returns:
            Tensorflow data set containing the specified type of data
        """
        datafile_name = "x_" + self._fname + "_" + data_type + ".npy"
        datafile_path = os.path.join(self._fpath, datafile_name)

        return np.load(datafile_path, mmap_mode="r+")

        # data = tf.data.TFRecordDataset(datafile_path)
        # data = self._ignore_order(data)
        # data = data.map(self._read_tfrecord, num_parallel_calls=tf.data.AUTOTUNE)
        # data.shuffle(buffer_size=self.buffer_size, seed=self.jet_seed)
        # data.prefetch(buffer_size=tf.data.AUTOTUNE)
        # data.batch(self.batch_size)

    def _load_target(self, data_type: str):
        """Load data from the data files generated by the pre-processing scripts.

        Set the batch size and apply shuffling at the jet level.

        Args:
            data_type: The type of data that you want to load: val, train or test.

        Returns:
            Tensorflow data set containing the specified type of data
        """
        datafile_name = "y_" + self._fname + "_" + data_type + ".npy"
        datafile_path = os.path.join(self._fpath, datafile_name)

        return np.load(datafile_path, mmap_mode="r+")

        # data = tf.data.TFRecordDataset(datafile_path)
        # data = self._ignore_order(data)
        # data = data.map(self._read_tfrecord, num_parallel_calls=tf.data.AUTOTUNE)
        # data.shuffle(buffer_size=self.buffer_size, seed=self.jet_seed)
        # data.prefetch(buffer_size=tf.data.AUTOTUNE)
        # data.batch(self.batch_size)

    # def _ignore_order(self, data: tf.data.TFRecordDataset):
    #     ignore_order = tf.data.Options()
    #     ignore_order.experimental_deterministic = False
    #     data = data.with_options(ignore_order)

    #     return data

    # def _read_tfrecord(self, example):
    #     tf_record_format = self._get_record_format(self.feats)
    #     example = tf.io.parse_single_example(example, tf_record_format)
    #     x_data = example["px"]
    #     y_data = example["label"]
    #     return x_data, y_data

    # def _get_record_format(self, feats: str):
    #     switcher = {
    #         "andre": lambda: self._andre_format(),
    #         "jedinet": lambda: self._jedinet_format(),
    #     }

    #     tfrecord_format = switcher.get(feats, lambda: None)()
    #     if tfrecord_format is None:
    #         raise TypeError("Feature selection name not valid!")

    #     return tfrecord_format

    # def _andre_format(self):
    #     return {
    #         "pt": tf.io.FixedLenFeature([], tf.float32),
    #         "eta": tf.io.FixedLenFeature([], tf.float32),
    #         "phi": tf.io.FixedLenFeature([], tf.float32),
    #         "label": tf.io.FixedLenFeature([], tf.float32),
    #     }

    # def _jedinet_format(self):
    #     return {
    #         "px": tf.io.FixedLenFeature([], tf.float32),
    #         "py": tf.io.FixedLenFeature([], tf.float32),
    #         "pz": tf.io.FixedLenFeature([], tf.float32),
    #         "E": tf.io.FixedLenFeature([], tf.float32),
    #         "Erel": tf.io.FixedLenFeature([], tf.float32),
    #         "pt": tf.io.FixedLenFeature([], tf.float32),
    #         "ptrel": tf.io.FixedLenFeature([], tf.float32),
    #         "eta": tf.io.FixedLenFeature([], tf.float32),
    #         "etarel": tf.io.FixedLenFeature([], tf.float32),
    #         "etarot": tf.io.FixedLenFeature([], tf.float32),
    #         "phi": tf.io.FixedLenFeature([], tf.float32),
    #         "phirel": tf.io.FixedLenFeature([], tf.float32),
    #         "phirot": tf.io.FixedLenFeature([], tf.float32),
    #         "deltaR": tf.io.FixedLenFeature([], tf.float32),
    #         "cos(theta)": tf.io.FixedLenFeature([], tf.float32),
    #         "cos(thetarel)": tf.io.FixedLenFeature([], tf.float32),
    #         "label": tf.io.FixedLenFeature([], tf.float32),
    #     }

    def _success_message(self):
        # Display success message for loading data when called.
        print("\n----------------")
        print(tcols.OKGREEN + "Data loading complete:" + tcols.ENDC)
        print(f"File name: {self._fname}")
        print(f"Training data size: {self.ntrain_jets:,}")
        print(f"Validation data size: {self.nvalid_jets:,}")
        print(f"Test data size: {self.ntest_jets:,}")
        print(f"Number of constituents: {self.ncons:,}")
        print(f"Number of features: {self.nfeat:,}")
        print("----------------\n")
